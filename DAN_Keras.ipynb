{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading data from google cloud"
      ],
      "metadata": {
        "id": "IR7K14_Ov9YI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyHKa3bNhty5",
        "outputId": "241bb2bb-467c-4601-e918-3129e9b2b608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-07-19 06:54:36--  https://storage.googleapis.com/kerascvnlp_data/young-affectnet-hq.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.170.128, 142.251.175.128, 172.253.118.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.170.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5441294496 (5.1G) [application/zip]\n",
            "Saving to: ‘young-affectnet-hq.zip’\n",
            "\n",
            "young-affectnet-hq. 100%[===================>]   5.07G  18.9MB/s    in 4m 44s  \n",
            "\n",
            "2023-07-19 06:59:20 (18.3 MB/s) - ‘young-affectnet-hq.zip’ saved [5441294496/5441294496]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/kerascvnlp_data/young-affectnet-hq.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CRW5ufU3Qsj"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/young-affectnet-hq.zip -d data/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the [DAN model ](https://arxiv.org/pdf/2109.07270.pdf)"
      ],
      "metadata": {
        "id": "-ZhCIAYowH-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALbPisTtWxPr",
        "outputId": "1e665d52-c401-45d8-a175-ee0f0602a56d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 8)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow.keras.layers as nn\n",
        "import keras\n",
        "\n",
        "class ChannelAttn(Layer):\n",
        "    def __init__(self, c=512) -> None:\n",
        "        super(ChannelAttn,self).__init__()\n",
        "        self.gap = nn.AveragePooling2D(7)\n",
        "        self.attention = Sequential([\n",
        "            nn.Dense(32),\n",
        "            nn.BatchNormalization(),\n",
        "            nn.ReLU(),\n",
        "            nn.Dense(c,activation='sigmoid')]\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        x = self.gap(x)\n",
        "        x = nn.Flatten()(x)\n",
        "        y = self.attention(x)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class SpatialAttn(Layer):\n",
        "    def __init__(self, c=512):\n",
        "        super(SpatialAttn,self).__init__()\n",
        "        self.conv1x1 = Sequential([\n",
        "            nn.Conv2D(256, 1),\n",
        "            nn.BatchNormalization()]\n",
        "        )\n",
        "        self.conv_3x3 = Sequential([\n",
        "            nn.ZeroPadding2D(padding=(1, 1)),\n",
        "            nn.Conv2D(512, 3,1),\n",
        "            nn.BatchNormalization()]\n",
        "        )\n",
        "        self.conv_1x3 = Sequential([\n",
        "            nn.ZeroPadding2D(padding=(0, 1)),\n",
        "            nn.Conv2D(512, (1,3)),\n",
        "            nn.BatchNormalization()]\n",
        "        )\n",
        "        self.conv_3x1 = Sequential([\n",
        "            nn.ZeroPadding2D(padding=(1, 0)),\n",
        "            nn.Conv2D(512,(3,1)),\n",
        "            nn.BatchNormalization()]\n",
        "        )\n",
        "        self.norm = nn.ReLU()\n",
        "\n",
        "    def call(self, x) :\n",
        "        y = self.conv1x1(x)\n",
        "        y = self.norm(self.conv_3x3(y) + self.conv_1x3(y) + self.conv_3x1(y))\n",
        "        y = tf.math.reduce_sum(y,axis=1, keepdims=True)\n",
        "        return x*y\n",
        "\n",
        "\n",
        "class CrossAttnHead(Layer):\n",
        "    def __init__(self, c=512):\n",
        "        super(CrossAttnHead,self).__init__()\n",
        "        self.sa = SpatialAttn(c)\n",
        "        self.ca = ChannelAttn(c)\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.ca(self.sa(x))\n",
        "\n",
        "\n",
        "\n",
        "class DAN(Model):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super(DAN,self).__init__()\n",
        "        self.mod = tf.keras.applications.ResNet50(\n",
        "            include_top=False,\n",
        "            weights=\"imagenet\",\n",
        "            input_shape=(224,224,3)\n",
        "        )\n",
        "        self.mod.trainable= False\n",
        "        self.num_head = 4\n",
        "        self.hd = CrossAttnHead()\n",
        "        self.hd=[]\n",
        "        for i in range(self.num_head):\n",
        "          self.hd.append(CrossAttnHead())\n",
        "        self.features = nn.Conv2D(512, 1,padding='same')\n",
        "        self.fc = nn.Dense(num_classes)\n",
        "        self.bn = nn.BatchNormalization()\n",
        "\n",
        "    def call(self, x) :\n",
        "        x = self.mod(x)\n",
        "        x=self.features(x)\n",
        "        heads = []\n",
        "        for h in self.hd:\n",
        "            heads.append(h(x))\n",
        "\n",
        "        heads = tf.transpose(tf.stack(heads),perm=(1,0,2))\n",
        "        heads = tf.nn.log_softmax(heads, axis=1)\n",
        "        out = self.bn(self.fc(tf.math.reduce_sum(heads,axis=1)))\n",
        "        return out\n",
        "\n",
        "model = DAN()\n",
        "img = tf.random.normal(shape=[10, 224, 224, 3])\n",
        "preds = model(img)\n",
        "print(preds.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating the image dataloader using the keras-core utils function"
      ],
      "metadata": {
        "id": "wcVEXZpmwR1P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-lfM07X386v",
        "outputId": "4d0e46d8-7ce6-49f1-becb-a6c544951bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14648 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=\"data/\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S-fYX5bf-Qhz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss=keras.losses.CategoricalCrossentropy())\n",
        "model.fit(train_generator,epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading the model using inbuilt functions of keras_core"
      ],
      "metadata": {
        "id": "rYr1Xx99vt3R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKxEstbn-zud"
      },
      "outputs": [],
      "source": [
        "model.save('weights/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYqcWuqkOJW7"
      },
      "outputs": [],
      "source": [
        "pb = keras.models.load_model('weights/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Kb428rOgga"
      },
      "outputs": [],
      "source": [
        "pred = pb(img)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzObYUiROqnJ"
      },
      "outputs": [],
      "source": [
        "!zip -r wgts.zip weights/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVUFuilbizMP"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/kerascvnlp_data/danwgts/wgts.zip\n",
        "!unzip wgts.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgLYD0Kd1Z_X",
        "outputId": "c963fe41-60f0-434b-e783-c2ea720236b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflite-support\n",
            "  Downloading tflite-support-0.1.0a1.tar.gz (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.4 (from tflite-support)\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflite-support) (1.22.4)\n",
            "Building wheels for collected packages: tflite-support\n",
            "  Building wheel for tflite-support (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflite-support: filename=tflite_support-0.1.0a1-cp310-cp310-linux_x86_64.whl size=5942401 sha256=c7e9b35b7492f34e69eee330b1b65e327b281488484e256ff208e30908d0ddbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/5c/da/9e5e661ec26e03ee57e69428d40fffbefe3c0aff649c55776d\n",
            "Successfully built tflite-support\n",
            "Installing collected packages: pybind11, tflite-support\n",
            "Successfully installed pybind11-2.10.4 tflite-support-0.1.0a1\n"
          ]
        }
      ],
      "source": [
        "!pip install tflite-support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ODbDxBn2hKV",
        "outputId": "8c1e5577-b1ad-445d-f3fe-61b8c70b5431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-26 16:26:33.200042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Finished populating metadata and associated file to the model:\n",
            "model.tflite\n",
            "The metadata json file has been saved to:\n",
            "/content/oiut/model.json\n",
            "The associated file that has been been packed to the model is:\n",
            "['labels.txt']\n"
          ]
        }
      ],
      "source": [
        "!python ./metadata_writer_for_image_classifier.py \\\n",
        "    --model_file=model.tflite \\\n",
        "    --label_file=labels.txt \\\n",
        "    --export_directory=/content/oiut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrDY-KX8Pify",
        "outputId": "606c229d-fb65-47b8-9e32-a4920cb7c273"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_41_layer_call_fn, conv2d_41_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, dense_21_layer_call_fn, dense_21_layer_call_and_return_conditional_losses while saving (showing 5 of 99). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the model\n",
        "pb = keras.models.load_model('weights/')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(pb) # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRabRedAC7mo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}